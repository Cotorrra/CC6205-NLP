{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:30:18.109327Z",
     "start_time": "2020-03-19T18:30:18.103344Z"
    }
   },
   "source": [
    "# Minitarea 1\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "Nombre: Joaquín Ignacio Pérez Araya\n",
    "\n",
    "Fecha de Entrega: Lunes 6 de Abril\n",
    "\n",
    "\n",
    "## Objetivos de la minitarea\n",
    "\n",
    "Este ejericio cuenta con varios objetivos principales: \n",
    "\n",
    "- Evaluar los contenidos de las primeras semanas de clases. En particular Information Retrieval (IR) y Vector Space Models. \n",
    "\n",
    "- Introducirlos a la programación en python enfocada en NLP.\n",
    "\n",
    "- Implementar un modelo básico de IR: *Term Frequency-Inverse Document Frequency (TF-IDF)*.\n",
    "\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "- El ejercicio consiste en:\n",
    "\n",
    "    - Responder preguntas relativas a los contenidos vistos en los videos y slides de las clases. \n",
    "    \n",
    "    - Implementar el modelo TF-IFD utilizando solo python, pandas y numpy. Está **PROHIBIDO** usar cualquier paquete que implemente dicho modelo (NLTK, spacy, scikit, etc...).\n",
    "\n",
    "- La minitarea es INDIVIDUAL.\n",
    "\n",
    "- Está demás decir que no se admiten copias, ni de código, ni de respuestas escritas. \n",
    "\n",
    "- La entrega debe ser por ucursos a mas tardar el día estipulado arriba. No se aceptan atrasos.\n",
    "\n",
    "- En el horario de auxiliar se abriran horarios de consulta en donde podrán preguntar acerca del ejercicio y en general, de todo el curso. \n",
    "\n",
    "- Cada punto equivale a 0.5 décimas de la nota de la minitarea.\n",
    "\n",
    "- Al revisar, tu código será ejecutado. Verifica que tu entrega no tenga errores.\n",
    "\n",
    "\n",
    "## Referencias\n",
    " \n",
    "Slides:\n",
    "    \n",
    "- [Introducción al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
    "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
    "\n",
    "Videos: \n",
    "\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Parte 1. \n",
    "\n",
    "La siguientes celdas contendrán preguntas acerca del contenido visto en clases y en el material del curso. La idea es contestar cada pregunta en su celda correspondiente. Las respuestas deben ser breves: máximo 3 lineas (salvo para la p3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P1) Son Natural Language Processing y Computational Linguistics lo mismo? (1 Punto)**\n",
    "\n",
    "  No, ya que el primero resulve problemas computacionales relacionados con el lenguaje humano y el segundo se dedica a estudiar el lenguaje en sí utilizando la computación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P2) Por qué estudiar el lenguaje humano es difícil? (1 Punto)**\n",
    "\n",
    "   Debido a que el lenguaje es altamente ambigüo y éste depende mucho del contexto para saber con exactitud cuál es el significado real de incluso la frase más mínima.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:45:25.544502Z",
     "start_time": "2020-03-19T18:45:25.537548Z"
    }
   },
   "source": [
    "\n",
    "**P3) Para el siguiente corpus:**\n",
    "\n",
    "    d1) I like human languages\n",
    "\n",
    "    d2) I like programming languages\n",
    "\n",
    "    d3) Spanish is my favorite language\n",
    "\n",
    "\n",
    "**Extraiga el vocabulario:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Solamente usando tokenization (1.5 puntos)**\n",
    "\n",
    "   Vocabulario: \\[I\\] \\[like\\]  \\[human\\]  \\[languages\\] \\[programming\\] \\[Spanish\\] \\[is\\] \\[my\\] \\[favorite\\] \\[language\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Usando stemming (proponga sus propias reglas de stemming) y borrado de stopwords (indique cuales son sus stopwords) (1.5 puntos)**\n",
    "\n",
    "Stopwords:  \\[I\\]  \\[like\\]  \\[is\\] \\[my\\] \n",
    "        \n",
    "Reglas de Stemming: Algoritmo de Porter\n",
    "\n",
    "| Transformaciones provocadas |\n",
    "|---------------------------------|\n",
    "|$programming \\to program$|\n",
    "|$languages/language \\to languag$|\n",
    "|$favorite \\to favorit$|\n",
    "\n",
    "\n",
    "Vocabulario: \\[human\\] \\[program\\] \\[Spanish\\] \\[favorit\\] \\[languag\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:46:24.015666Z",
     "start_time": "2020-03-19T18:46:24.010706Z"
    }
   },
   "source": [
    "**P4) Conceptualmente cuál es la diferencia entre usar machine learning clásico (empirismo) y deep learning para un problema de NLP (Puede usar el análisis de sentimientos como ejemplo) (1 punto)**\n",
    "\n",
    "Para machine learning clásico se necesita procesamiento adicional del corpus a trabajar antes de procesar, \n",
    "usando deep learning este proceso no existe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:47:04.360754Z",
     "start_time": "2020-03-19T18:47:04.357763Z"
    }
   },
   "source": [
    "--------------\n",
    "\n",
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:57:05.868104Z",
     "start_time": "2020-03-19T18:57:05.863117Z"
    }
   },
   "source": [
    "Impementar TF-IDF. \n",
    "\n",
    "Esta parte, cada celda representa una función distinta por implementar. Se usará pandas para representar las matrices y arreglos que vayamos calculando. Siguiente a cada celda con una función por implementar habrá un ejemplo de como debería ser el output que tienen que lograr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.618054Z",
     "start_time": "2020-03-23T14:11:57.813136Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset, cada string representa un documento. Observación: Corpus = Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.637916Z",
     "start_time": "2020-03-23T14:11:58.618054Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    't4 t3 t1 t4', 't5 t4 t2 t3 t5', 't2 t1 t4 t4', 't2 t3 t3 t1 t4',\n",
    "    't1 t4 t2 t2', 't2 t3 t2 t3 t2 t3'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtener vocabulario (1 punto)** \n",
    "\n",
    "Implementar la función `get_vocab(dataset)` que recibe el dataset y retorna un arreglo con cada palabra que aparece en el dataset. (sin duplicar). Observación: vocabulario = types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.657732Z",
     "start_time": "2020-03-23T14:11:58.637916Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(dataset):\n",
    "    array = np.array([])\n",
    "    for text in dataset:\n",
    "        text = text.split(\" \")\n",
    "        for word in text:\n",
    "            word = word.lower()\n",
    "            if not word in array:\n",
    "                array = np.append(array, word)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.671780Z",
     "start_time": "2020-03-23T14:11:58.657732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['t4', 't3', 't1', 't5', 't2'], dtype='<U32')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(dataset)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular Bag of Words (bow) (2 puntos)**\n",
    "\n",
    "Implementar la función `calc_bow(dataset, vocab)` que toma el dataset y el vocabulario calculado en la parte anterior y retorna un pandas DataFrame en donde las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabra los documento. En otras palabras, cada fila representa el bow de un determinado documento\n",
    "\n",
    "el bow de cada documento.\n",
    "\n",
    "Recordatorio - Bag of Words: Cuenta las apariciones de cada palabra en cada uno de los documentos. Por ejemplo:\n",
    "\n",
    "Por ejemplo, para los documentos: \n",
    "\n",
    "```\n",
    "d_0 = 'El perro ladra'\n",
    "d_1 = 'El perro come'\n",
    "\n",
    "```\n",
    "\n",
    "Deberíamos retornar:\n",
    "\n",
    "|   .  | el | perro | ladra | come  |\n",
    "|-----|----|-------|-------|-------|\n",
    "| d_0 | 1  | 1     | 1     | 0     |\n",
    "| d_1 | 1  | 1     | 0     | 1     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.680740Z",
     "start_time": "2020-03-23T14:11:58.673758Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bow(dataset, vocab):\n",
    "    bow = {}\n",
    "    for word in vocab:\n",
    "        bow[word] = np.zeros(len(dataset))\n",
    "        \n",
    "    for i in range(len(dataset)):\n",
    "        tokens = dataset[i].split(\" \") # Tokenizacion lvl-0\n",
    "        for token in tokens:\n",
    "            token = token.lower()    \n",
    "            bow[token][i] += 1\n",
    "            \n",
    "    df = pd.DataFrame(data=bow)\n",
    "    return df\n",
    "\n",
    "dataset_bow = calc_bow(dataset, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.694719Z",
     "start_time": "2020-03-23T14:11:58.683734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    t4   t3   t1   t5   t2\n0  2.0  1.0  1.0  0.0  0.0\n1  1.0  1.0  0.0  2.0  1.0\n2  2.0  0.0  1.0  0.0  1.0\n3  1.0  2.0  1.0  0.0  1.0\n4  1.0  0.0  1.0  0.0  2.0\n5  0.0  3.0  0.0  0.0  3.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t4</th>\n      <th>t3</th>\n      <th>t1</th>\n      <th>t5</th>\n      <th>t2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T14:27:01.721767Z",
     "start_time": "2020-03-20T14:27:01.716781Z"
    }
   },
   "source": [
    "**Calcular TF (1 punto)**\n",
    "\n",
    "En esta sección debemos usar el dataframe calcular la matriz de TF normalizada por el máximo $\\text{ntf}_{i,j}$. Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca mas veces ese vector. \n",
    "\n",
    "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.717795Z",
     "start_time": "2020-03-23T14:11:58.697765Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_tf(dataset_bow):\n",
    "    return dataset_bow.apply(lambda row: row / np.max(row), axis=1)\n",
    "\n",
    "tf = calc_tf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.737943Z",
     "start_time": "2020-03-23T14:11:58.717795Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    t4   t3   t1   t5   t2\n0  1.0  0.5  0.5  0.0  0.0\n1  0.5  0.5  0.0  1.0  0.5\n2  1.0  0.0  0.5  0.0  0.5\n3  0.5  1.0  0.5  0.0  0.5\n4  0.5  0.0  0.5  0.0  1.0\n5  0.0  1.0  0.0  0.0  1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t4</th>\n      <th>t3</th>\n      <th>t1</th>\n      <th>t5</th>\n      <th>t2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular IDF (1 punto)**\n",
    "\n",
    "\n",
    "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
    "\n",
    "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ número de documentos y $n_i = $ Número de documentos que contienen la palabra $t_i$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.777595Z",
     "start_time": "2020-03-23T14:11:58.737943Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_idf(dataset_bow):\n",
    "    # es necesario que sea un dict?\n",
    "    dataset_len = len(dataset_bow.index)\n",
    "    count = dataset_bow.apply(lambda col: np.count_nonzero(col))\n",
    "    count = count.apply(lambda col: dataset_len / col)\n",
    "    count = count.apply(lambda col: np.log10(col))\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "idf = calc_idf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.792834Z",
     "start_time": "2020-03-23T14:11:58.777595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "t4    0.079181\nt3    0.176091\nt1    0.176091\nt5    0.778151\nt2    0.079181\ndtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular TF-IDF (1 punto)**\n",
    "\n",
    "Por último, implementar `calc_tf_idf(tf, idf)`. Esta debe cumplir que \n",
    "\n",
    "$$tf{-}idf = tf_{i,j} * idf_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.817896Z",
     "start_time": "2020-03-23T14:11:58.792834Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf_idf(tf, idf):\n",
    "    return tf * idf\n",
    "\n",
    "tf_idf = calc_tf_idf(tf, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.837641Z",
     "start_time": "2020-03-23T14:11:58.817896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         t4        t3        t1        t5        t2\n0  0.079181  0.088046  0.088046  0.000000  0.000000\n1  0.039591  0.088046  0.000000  0.778151  0.039591\n2  0.079181  0.000000  0.088046  0.000000  0.039591\n3  0.039591  0.176091  0.088046  0.000000  0.039591\n4  0.039591  0.000000  0.088046  0.000000  0.079181\n5  0.000000  0.176091  0.000000  0.000000  0.079181",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t4</th>\n      <th>t3</th>\n      <th>t1</th>\n      <th>t5</th>\n      <th>t2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.079181</td>\n      <td>0.088046</td>\n      <td>0.088046</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.039591</td>\n      <td>0.088046</td>\n      <td>0.000000</td>\n      <td>0.778151</td>\n      <td>0.039591</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.079181</td>\n      <td>0.000000</td>\n      <td>0.088046</td>\n      <td>0.000000</td>\n      <td>0.039591</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.039591</td>\n      <td>0.176091</td>\n      <td>0.088046</td>\n      <td>0.000000</td>\n      <td>0.039591</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.039591</td>\n      <td>0.000000</td>\n      <td>0.088046</td>\n      <td>0.000000</td>\n      <td>0.079181</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.176091</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.079181</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus: Hacer una función para realizar una Query (2 puntos extra)**\n",
    "\n",
    "`calc_query(query, dataset)` función debe retornar un ranking con los documentos mas relevantes para la palabra consultada. \n",
    "\n",
    "Sugerencias:\n",
    "\n",
    "- Primero, recalcular la matriz TF-IDF usando el dataset mas la query. Usen las funciones anteriores para calcular la matriz.\n",
    "- Luego, usar similitud coseno para comparar los documentos ya precalculados y la consulta. (deben implementar dicha función usando las herramientas básicas de numpy).\n",
    "- A partir de eso, retornar un ranking con los documentos mas similares.\n",
    "\n",
    "Deben reportar por lo menos 2 ejemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T13:06:17.829181Z",
     "start_time": "2020-03-24T13:06:17.825192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-e4260fb37086>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0msim_matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[0mcalc_query\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"t4\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-13-e4260fb37086>\u001B[0m in \u001B[0;36mcalc_query\u001B[1;34m(query, dataset)\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mtf_idf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtf_idf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mcos_sim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m     \u001B[0msim_matrix\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_idf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcos_sim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mquery_tf_idf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0msim_matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001B[0m\n\u001B[0;32m   6874\u001B[0m             \u001B[0mresult_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mresult_type\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6875\u001B[0m             \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6876\u001B[1;33m             \u001B[0mkwds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   6877\u001B[0m         )\n\u001B[0;32m   6878\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mframe_apply\u001B[1;34m(obj, func, axis, raw, result_type, ignore_failures, args, kwds)\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[0mignore_failures\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_failures\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m         \u001B[0mkwds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m     )\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, obj, func, raw, result_type, ignore_failures, args, kwds)\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mraw\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mignore_failures\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mignore_failures\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     99\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkwds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def calc_query(query, dataset):\n",
    "    new_dataset = np.append(dataset,query)\n",
    "    vocab = get_vocab(new_dataset)\n",
    "    bow = calc_bow(new_dataset, vocab)\n",
    "    tf = calc_tf(bow)\n",
    "    idf = calc_idf(bow)\n",
    "    tf_idf = calc_tf_idf(tf, idf)\n",
    "    \n",
    "    query_tf_idf = tf_idf.tail(1).to_numpy()\n",
    "    tf_idf.drop([tf_idf.shape[0] - 1], axis=0)\n",
    "    cos_sim = lambda x, y: np.inner(x, y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "    sim_matrix = tf_idf.apply(cos_sim, args = query_tf_idf)\n",
    "    \n",
    "    return sim_matrix\n",
    "\n",
    "calc_query(\"t4\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usar dato reales (Opcional, sin puntaje)**\n",
    "\n",
    "Adicionalmente, existe la alternativa de probar tu implementación de tf-idf con un dataset de noticias:\n",
    "\n",
    "El modelo que creaste anteriormente no debería dejar de funcionar si cargas este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:42.470019Z",
     "start_time": "2020-03-23T14:11:33.935341Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "BASE_URL = 'https://github.com/dccuchile/CC6205/releases/download/Data/{}.json'\n",
    "\n",
    "dataset = pd.concat([\n",
    "    pd.read_json(BASE_URL.format('biobio_nacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_opinion')),\n",
    "    pd.read_json(BASE_URL.format('biobio_internacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_sociedad')),\n",
    "    pd.read_json(BASE_URL.format('biobio_economia'))\n",
    "])\n",
    "\n",
    "\n",
    "def clean_doc(doc):\n",
    "    return ' '.join(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda x: x != '',\n",
    "                re.sub(\"\\?|\\¿|\\:|\\!|\\¡|\\(|\\)|\\t|\\n|“|”|\\\"|\\'|\\s\\s+|\\.|\\,|\\;\",\n",
    "                       \" \", doc.lower()).split(' '))))\n",
    "\n",
    "\n",
    "dataset = list(\n",
    "    map(lambda x: clean_doc(x[0] + '.' + x[1]), dataset[['title',\n",
    "                                                         'content']].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-959495b3",
   "language": "python",
   "display_name": "PyCharm (CC6205-NLP)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}