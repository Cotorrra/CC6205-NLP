{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-959495b3",
   "language": "python",
   "display_name": "PyCharm (CC6205-NLP)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "colab": {
   "name": "t1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:49:08.174519Z",
     "start_time": "2020-03-31T13:49:08.165989Z"
    },
    "id": "G2G9R-pQvKbr",
    "colab_type": "text"
   },
   "source": [
    "# Tarea 1 NLP : Competencia de Clasificación de Texto\n",
    "-------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCrkqG4JvKbz",
    "colab_type": "text"
   },
   "source": [
    "- **Nombres:** Valentina Sepulveda, Joaquín Pérez\n",
    "\n",
    "- **Usuario o nombre de equipo en Codalab:** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T14:34:38.796217Z",
     "start_time": "2020-04-07T14:34:38.782255Z"
    },
    "id": "7h1JBoHEvKcI",
    "colab_type": "text"
   },
   "source": [
    "### Detalles e instrucciones de la competencia:\n",
    "\n",
    "- La competencia consiste en resolver 4 problemas de clasificación distintos, cada uno de tres clases. Por cada problema deberán crear un clasificador distinto. La evaluación de la competencia se realiza en base a 4 métricas: AUC, Kappa y Accuracy. Los mejores puntajes en cada ítem serán los que ganen.\n",
    "\n",
    "- Para comenzar se les entregará en este notebook el baseline y la estructura del reporte. El baseline es el código que realiza creación de features y clasificación básica. Los puntajes de este serán ocupados como base para la competencia: deben superar sus resultados para ser bien evaluados.  \n",
    "\n",
    "- Para participar, deben registrarse en Codalab y luego ingresar a la competencia usando el siguiente [link]( https://competitions.codalab.org/competitions/24121?secret_key=f5eb2d95-b36e-4aad-8fc5-4d9d77f4e4dc). \n",
    "\n",
    "- **Es requisito entregar el reporte con el código y haber participado en la competencia para ser evaluado.**\n",
    "\n",
    "- Pueden hacer grupos de máximo 2 alumnos. Cada grupo debe tener un nombre de equipo (En codalab, ir a settings y después cambiar Team Name). Solo una persona debe administrar la cuenta del grupo.\n",
    "\n",
    "- En total pueden hacer un **máximo de 4 envíos/submissions** (tanto para equipos como para envíos indivuales).\n",
    "\n",
    "- Hagan varios experimentos haciendo cross-validation o evaluación sobre una sub-partición antes de enviar sus predicciones a Codalab. Asegúrense que la distribución de las clases sea balanceada en las particiones de training y testing. Verificar que el formato de la submission coincida con el de la competencia. De lo contrario, se les será evaluado incorrectamente.\n",
    "\n",
    "- Estar top 5 en alguna métrica equivale a 1 punto extra en la nota final.\n",
    "\n",
    "- No se limiten a los contenidos vistos ni a scikit ni a este baseline. ¡Usen todo su conocimiento e ingenio en mejorar sus sistemas! \n",
    "\n",
    "- Todas las dudas escríbanlas en el hilo de U-cursos de la tarea. Los emails que lleguen al equipo docente serán remitidos a ese medio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8W8H7JKvKcO",
    "colab_type": "text"
   },
   "source": [
    "### Reporte\n",
    "\n",
    "Este debe cumplir la siguiente estructura:\n",
    "\n",
    "1.\t**Introducción**: Presentar brevemente el problema a resolver, los métodos y representaciones utilizadas en el desarrollo de la tarea y conclusiones obtenidas. (0.5 Puntos)\n",
    "2.\t**Representaciones**: Describir los atributos y representaciones usadas como entrada de los clasificadores. Si bien, con Bag of Words (baseline) ya se comienzan a percibir buenos resultados, pueden mejorar su evaluación agregando más atributos y representaciones diseñadas a mano. Mas abajo encontrarán una lista útil de estos que les podrá ser de utilidad. (1.5 puntos)\n",
    "3.\t**Algoritmos**: Describir brevemente los algoritmos de clasificación usados. (0.5 puntos)\n",
    "4.\t**Métricas de evaluación**: Describir brevemente las métricas utilizadas en la evaluación indicando que miden y su interpretación. (0.5 puntos)\n",
    "5.\t**Experimentos**: Reportar todos sus experimentos. Comparar los resultados obtenidos utilizando diferentes algoritmos y representaciones. Estos experimentos los hacen sobre la sub-partición de evaluación que deben crear (o pueden usar cross-validation). Incluyan todo el código de sus experimentos aquí. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (2 puntos)\n",
    "6.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:18:43.301002Z",
     "start_time": "2019-08-21T19:18:43.298037Z"
    },
    "id": "UQ53VkYdvKcU",
    "colab_type": "text"
   },
   "source": [
    "### Baseline\n",
    "\n",
    "Por último, el baseline contiene un código básico que:\n",
    "\n",
    "- Obtiene los dataset.\n",
    "- Divide los datasets en train (entrenamiento y prueba) y target set (el que clasificar para subir a la competencia).\n",
    "- Crea un Pipeline que: \n",
    "    - Crea features personalizadas.\n",
    "    - Transforma los dataset a bag of words (BoW).  \n",
    "    - Entrena un clasificador usando cada train set.\n",
    "- Clasifica y evalua el sistema creado usando el test set.\n",
    "- Clasifica el target set.\n",
    "- Genera una submission con el target en formato zip en el directorio en donde se está ejecutando el notebook. \n",
    "\n",
    "\n",
    "Algunas pistas sobre como mejorar el rendimiento de los sistemas que creen. (Esto tendrá mas sentido cuando vean el código)\n",
    "\n",
    "- **Vectorizador**: investigar los modulos de `nltk`, en particular, `TweetTokenizer`, `mark_negation` para reemplazar los tokenizadores. También, el parámetro `ngram_range` (Ojo que el clf naive bayes no debería usarse con n-gramas, ya que rompe el supuesto de independencia). Además, implementar los atributos que crean útiles desde el listado del el enunciado. Investigar también el vectorizador tf-idf.\n",
    "\n",
    "- **Clasificador**: investigar otros clasificadores mas efectivos que naive bayes. Estos deben poder retornar la probabilidad de pertenecia de las clases (ie: implementar la función `predict_proba`).\n",
    "\n",
    "- **Features**: Recuerden que pueden implementar todas las features que se les ocurra! Aquí les adjuntamos algunos ejemplos:\n",
    "    -\tWord n-grams.\n",
    "    -\tCharacter n-grams. \n",
    "    -\tPart-of-speech tags.\n",
    "    -\tSentiment Lexicons (Lexicon = A set of words with a label or associated value.).\n",
    "        - Count the number of positive and negative words within a sentence.\n",
    "        - If the lexicon has associated intensity of feeling (for example in a decimal), then take the average of the intensity of the sentence according to the feeling, the sum, etc.\n",
    "        -\tA good lexicon of sentiment: [Bing Liu](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar) \n",
    "        - A reference with a lot of [sentiment lexicons](https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-1-positive-and-negative-words-databases-ae35431a470c). \n",
    "    -\tThe number of elongated words (words with one character repeated more than two times).\n",
    "    -\tThe number of words with all characters in uppercase.\n",
    "    -\tThe presence and the number of positive or negative emoticons.\n",
    "    -\tThe number of individual negations.\n",
    "    -\tThe number of contiguous sequences of dots, question marks and exclamation marks.\n",
    "    -\tWord Embeddings: Here are some good ideas on how to use them.\n",
    "    https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector\n",
    "\n",
    "- **Reducción de dimensionalidad**: También puede serles de ayuda. Referencias [aquí](https://scikit-learn.org/stable/modules/unsupervised_reduction.html).\n",
    "\n",
    "- Por último, pueden encontrar mas referencias de cómo mejorar sus features, el vectorizador y el clasificador [aquí](https://affectivetweets.cms.waikato.ac.nz/benchmark/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GGbVakLvKcn",
    "colab_type": "text"
   },
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIDyXa6f-HgY",
    "colab_type": "text"
   },
   "source": [
    "# 0. TODO\n",
    "- Encontrar un bonito clasificador para las features.\n",
    "- Modificar la funcion run para considerar las nuevos datasets balanceados.\n",
    "- Experimentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:34:25.683540Z",
     "start_time": "2020-03-31T13:34:25.673430Z"
    },
    "id": "TGUTH412vKct",
    "colab_type": "text"
   },
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:47:13.474238Z",
     "start_time": "2020-03-31T13:47:13.454068Z"
    },
    "id": "BJobCgn5vKc1",
    "colab_type": "text"
   },
   "source": [
    "## 2. Representaciones\n",
    "\n",
    "Para las representaciones se escogio..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RDLeGcSvKc-",
    "colab_type": "text"
   },
   "source": [
    "## 3. Algoritmos\n",
    "\n",
    "De los algoritmos de clasificación se decidió..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQSGEDwqvKdM",
    "colab_type": "text"
   },
   "source": [
    "## 4. Métricas de Evaluación\n",
    "\n",
    "- AUC: ...\n",
    "- Kappa: El coeficiente kappa de Cohen es una métrica que establece qué tan certero es el clasificador con los resultados esperados teniendo en cuenta la posibilidad de que las predicciones acertadas pudieron haber sido por mero azar.\n",
    "\n",
    "- Accuracy: El Accuracy mide la proporción de aciertos del clasificador de forma simple, contando la cantidad de clases bien predichas versus la cantidad de predicciones realizadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x_qQLaHvKdQ",
    "colab_type": "text"
   },
   "source": [
    "## 5. Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:31:40.023344Z",
     "start_time": "2020-03-31T13:31:40.003541Z"
    },
    "id": "_JSwCF_bvKdY",
    "colab_type": "text"
   },
   "source": [
    "### Importar librerías y utiles"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EXzxb-SpATDg",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Set-up\n",
    "try:\n",
    "    import emojis\n",
    "except:\n",
    "    !pip install emojis\n",
    "    import emojis\n",
    "\n",
    "try:\n",
    "    import gensim.downloader as api\n",
    "except:\n",
    "    !pip install gensim\n",
    "\n",
    "# !pip install -U imbalanced-learn"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:20.587160Z",
     "start_time": "2020-04-07T15:44:19.319386Z"
    },
    "id": "2HRJf2t7vKdc",
    "colab_type": "code",
    "outputId": "9f4e1310-da03-40f1-d647-8a445263277c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "import emojis\n",
    "import gensim.downloader as api # https://github.com/RaRe-Technologies/gensim-data\n",
    "# get the model\n",
    "model = api.load(\"glove-twitter-25\")\n",
    "\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJiP8jlOvKd1",
    "colab_type": "text"
   },
   "source": [
    "### Definir métodos de evaluación\n",
    "\n",
    "Estas funciones están a cargo de evaluar los resultados de la tarea. No deberían cambiarlas.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:20.604066Z",
     "start_time": "2020-04-07T15:44:20.589106Z"
    },
    "id": "SMWRq5nPvKeA",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def auc_score(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array(\n",
    "        [prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w\n",
    "\n",
    "\n",
    "def evaulate(predicted_probabilities, y_test, labels, dataset_name):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "    print('Confusion Matrix for {}:\\n'.format(dataset_name))\n",
    "    print(\n",
    "        confusion_matrix(y_test,\n",
    "                         predicted_labels,\n",
    "                         labels=['low', 'medium', 'high']))\n",
    "\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(\n",
    "        classification_report(y_test,\n",
    "                              predicted_labels,\n",
    "                              labels=['low', 'medium', 'high']))\n",
    "    # Reorder predicted probabilities array.\n",
    "    labels = labels.tolist()\n",
    "    predicted_probabilities = predicted_probabilities[:, [\n",
    "        labels.index('low'),\n",
    "        labels.index('medium'),\n",
    "        labels.index('high')\n",
    "    ]]\n",
    "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
    "    print(\"Scores:\\n\\nAUC: \", auc, end='\\t')\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end='\\t')\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print('------------------------------------------------------\\n')\n",
    "    return np.array([auc, kappa, accuracy])"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK3Srgqu_yTI",
    "colab_type": "text"
   },
   "source": [
    "### Datos ####"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FauIAEaMqBRS",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    "# Datasets de entrenamiento.\n",
    "train = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/anger-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/fear-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/joy-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/sadness-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'])\n",
    "}\n",
    "# Datasets que deberán predecir para la competencia.\n",
    "target = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/anger-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/fear-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/joy-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/sadness-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE'])\n",
    "}"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DoBu0XyvKfG",
    "colab_type": "text"
   },
   "source": [
    "### Analizar los datos \n",
    "\n",
    "Imprimir la cantidad de tweets de cada dataset, según su intensidad de sentimiento. Noten que las clases están desbalanceadas. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.117633Z",
     "start_time": "2020-04-07T15:44:21.090703Z"
    },
    "id": "iLit4HlFvKfK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_group_dist(group_name, train):\n",
    "    print(group_name, \"\\n\",\n",
    "          train[group_name].groupby('sentiment_intensity').count(),\n",
    "          '\\n---------------------------------------\\n')\n",
    "for dataset_name in train:\n",
    "    get_group_dist(dataset_name, train)"
   ],
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 163    163    163\n",
      "low                  161    161    161\n",
      "medium               617    617    617 \n",
      "---------------------------------------\n",
      "\n",
      "fear \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 270    270    270\n",
      "low                  288    288    288\n",
      "medium               699    699    699 \n",
      "---------------------------------------\n",
      "\n",
      "joy \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 195    195    195\n",
      "low                  219    219    219\n",
      "medium               488    488    488 \n",
      "---------------------------------------\n",
      "\n",
      "sadness \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 197    197    197\n",
      "low                  210    210    210\n",
      "medium               453    453    453 \n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyqmE30oCAxc",
    "colab_type": "text"
   },
   "source": [
    "### Balance de Clases"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q0aQopQlMCI9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.utils import resample"
   ],
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVE8N1M-LxNa",
    "colab_type": "text"
   },
   "source": [
    "#### Clasificador de Enojo ####"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V5W2njtMLuXf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "enojo=train.get('anger')\n",
    "df_enojo_high=enojo['sentiment_intensity']=='high'\n",
    "df_enojo_high=enojo[df_enojo_high]\n",
    "df_enojo_medium=enojo['sentiment_intensity']=='medium'\n",
    "df_enojo_medium=enojo[df_enojo_medium]\n",
    "df_enojo_low=enojo['sentiment_intensity']=='low'\n",
    "df_enojo_low=enojo[df_enojo_low]"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sdLSYDcnMfdV",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Downsample de medium\n",
    "df_majority_downsampled = resample(df_enojo_medium, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=163,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Se combinan las clases minoritarias con la mayoritaria\n",
    "df_downsampled_enojo = pd.concat([df_majority_downsampled, df_enojo_low,df_enojo_high])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled_enojo.sentiment_intensity.value_counts()"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "high      163\nmedium    163\nlow       161\nName: sentiment_intensity, dtype: int64"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWa2mMxqMFpF",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Clasificador de Miedo ####"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TQ2aWlpkMJTS",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "miedo=train.get('fear')\n",
    "df_miedo_high=miedo['sentiment_intensity']=='high'\n",
    "df_miedo_high=miedo[df_miedo_high]\n",
    "df_miedo_medium=miedo['sentiment_intensity']=='medium'\n",
    "df_miedo_medium=miedo[df_miedo_medium]\n",
    "df_miedo_low=miedo['sentiment_intensity']=='low'\n",
    "df_miedo_low=miedo[df_miedo_low]"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gtGfh2nXMpmw",
    "colab_type": "code",
    "outputId": "ac7a085a-8bfc-487f-85fa-68634a3ecbbd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    }
   },
   "source": [
    "# Downsample de medium\n",
    "df_majority_downsampled = resample(df_miedo_medium, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=270,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Se combinan las clases minoritarias con la mayoritaria\n",
    "df_downsampled_miedo = pd.concat([df_majority_downsampled, df_miedo_low,df_miedo_high])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled_miedo.sentiment_intensity.value_counts()"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "low       288\nhigh      270\nmedium    270\nName: sentiment_intensity, dtype: int64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTxcwlYPMJ2R",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Clasificador de Alegria ####"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y8-X-zI9MPCI",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "alegria=train.get('joy')\n",
    "df_alegria_high=alegria['sentiment_intensity']=='high'\n",
    "df_alegria_high=alegria[df_alegria_high]\n",
    "df_alegria_medium=alegria['sentiment_intensity']=='medium'\n",
    "df_alegria_medium=alegria[df_alegria_medium]\n",
    "df_alegria_low=alegria['sentiment_intensity']=='low'\n",
    "df_alegria_low=alegria[df_alegria_low]"
   ],
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z2GtRRsjMxl6",
    "colab_type": "code",
    "outputId": "adb7530a-978d-4835-b22e-034e1341ced4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Downsample de medium\n",
    "df_majority_downsampled = resample(df_alegria_medium, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=200,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Se combinan las clases minoritarias con la mayoritaria\n",
    "df_downsampled_alegria = pd.concat([df_majority_downsampled, df_alegria_low,df_alegria_high])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled_alegria.sentiment_intensity.value_counts()"
   ],
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "low       219\nmedium    200\nhigh      195\nName: sentiment_intensity, dtype: int64"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDGQQ33AMPlF",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Clasificador de Tristeza ####"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vSojyA1iMVzH",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "tristeza=train.get('sadness')\n",
    "df_tristeza_high=tristeza['sentiment_intensity']=='high'\n",
    "df_tristeza_high=tristeza[df_tristeza_high]\n",
    "df_tristeza_medium=tristeza['sentiment_intensity']=='medium'\n",
    "df_tristeza_medium=tristeza[df_tristeza_medium]\n",
    "df_tristeza_low=tristeza['sentiment_intensity']=='low'\n",
    "df_tristeza_low=tristeza[df_tristeza_low]"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q4uZZCk5M4y7",
    "colab_type": "code",
    "outputId": "7823074e-da4a-4694-8f71-191cff5a7488",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    }
   },
   "source": [
    "# Downsample de medium\n",
    "df_majority_downsampled = resample(df_tristeza_medium, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=200,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Se combinan las clases minoritarias con la mayoritaria\n",
    "df_downsampled_tristeza = pd.concat([df_majority_downsampled, df_tristeza_low,df_tristeza_high])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled_tristeza.sentiment_intensity.value_counts()"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "low       210\nmedium    200\nhigh      197\nName: sentiment_intensity, dtype: int64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPIcYA2IM8jt",
    "colab_type": "text"
   },
   "source": [
    "#### Features y Estimadores"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.128600Z",
     "start_time": "2020-04-07T15:44:21.119624Z"
    },
    "id": "LsOWDM_8vKft",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Feature de ejemplo\n",
    "# https://scikit-learn.org/stable/data_transforms.html\n",
    "class CharsCountTransformer(BaseEstimator, TransformerMixin):\n",
    "    def get_relevant_chars(self, tweet):\n",
    "        num_hashtags = tweet.count('#')       #\n",
    "        num_exclamations = tweet.count('!')   #\n",
    "        num_interrogations = tweet.count('?') #\n",
    "        num_dots = tweet.count('.')           #\n",
    "        num_emojis = emojis.count(tweet)      #\n",
    "        return [num_hashtags, num_exclamations, num_interrogations, num_emojis, num_dots]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        chars = []\n",
    "        for tweet in X:\n",
    "            chars.append(self.get_relevant_chars(tweet))\n",
    "\n",
    "        return np.array(chars)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "class WordEmbeddingsTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Usa el diccionario y encuentra su origen\n",
    "    def __init__(self, model):\n",
    "      self.model = model\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        aggregation = np.mean\n",
    "        tokenizer = TweetTokenizer()\n",
    "        doc_embeddings = []\n",
    "        for tweet in X:\n",
    "            tokens = tokenizer.tokenize(tweet)\n",
    "            selected_words = []\n",
    "            for token in tokens:\n",
    "                if token in model.vocab:\n",
    "                    selected_words.append(model[token])\n",
    "            \n",
    "            if len(selected_words) > 0:\n",
    "                doc_emb = aggregation(np.array(selected_words), axis = 0)\n",
    "                doc_embeddings.append(doc_emb)\n",
    "            else:\n",
    "                doc_embeddings.append(np.zeros(model.vector_size))\n",
    "\n",
    "        return np.array(doc_embeddings)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "# Template para una feature\n",
    "class SentimentLexicon(BaseEstimator, TransformerMixin):\n",
    "    def fun(self, tweet):\n",
    "        # do something...\n",
    "        return [0]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(tweet)\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "# Estimator\n",
    "estimator = OneVsRestClassifier(LogisticRegression(max_iter=1000000))\n",
    "# estimator = LogisticRegression(max_iter=1000000)\n",
    "        "
   ],
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Pipeline ####"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def sad_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([('bow', CountVectorizer()),\n",
    "                                    ('chars_count', CharsCountTransformer()),\n",
    "                                    ('word_embeddings', WordEmbeddingsTransformer(model))\n",
    "                                    ])), ('clf', estimator)])\n",
    "\n",
    "def angry_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([('bow', CountVectorizer()),\n",
    "                                    ('chars_count', CharsCountTransformer()),\n",
    "                                    ('word_embeddings', WordEmbeddingsTransformer(model))\n",
    "                                    ])), ('clf', estimator)])\n",
    "    \n",
    "def fear_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([('bow', CountVectorizer()),\n",
    "                                    ('chars_count', CharsCountTransformer()),\n",
    "                                    ('word_embeddings', WordEmbeddingsTransformer(model))\n",
    "                                    ])), ('clf', estimator)])\n",
    "\n",
    "def joy_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([('bow', CountVectorizer()),\n",
    "                                    ('chars_count', CharsCountTransformer()),\n",
    "                                    ('word_embeddings', WordEmbeddingsTransformer(model))\n",
    "                                    ])), ('clf', estimator)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Ejecutar el pipeline para algun data-set\n",
    "def run(dataset, dataset_name, pipeline):\n",
    "    \"\"\"Creamos el pipeline y luego lo ejecutamos el pipeline sobre un dataset. \n",
    "    Retorna el modelo ya entrenado mas sus labels asociadas y los scores obtenidos al evaluarlo.\"\"\"\n",
    "\n",
    "    # Dividimos el dataset en train y test.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset.tweet,\n",
    "        dataset.sentiment_intensity,\n",
    "        shuffle=True,\n",
    "        test_size=0.33)\n",
    "\n",
    "    # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
    "    predicted_probabilities = pipeline.predict_proba(X_test)\n",
    "\n",
    "    # Obtenemos el orden de las clases aprendidas.\n",
    "    learned_labels = pipeline.classes_\n",
    "\n",
    "    # Evaluamos:\n",
    "    scores = evaulate(predicted_probabilities, y_test, learned_labels, dataset_name)\n",
    "    return pipeline, learned_labels, scores\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for anger:\n",
      "\n",
      "[[29 21  9]\n",
      " [21 20 15]\n",
      " [ 1 12 33]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.57      0.49      0.53        59\n",
      "      medium       0.38      0.36      0.37        56\n",
      "        high       0.58      0.72      0.64        46\n",
      "\n",
      "    accuracy                           0.51       161\n",
      "   macro avg       0.51      0.52      0.51       161\n",
      "weighted avg       0.51      0.51      0.50       161\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.695\tKappa: 0.266\tAccuracy: 0.509\n",
      "------------------------------------------------------\n",
      "\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[48 31 12]\n",
      " [24 41 24]\n",
      " [13 22 59]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.56      0.53      0.55        91\n",
      "      medium       0.44      0.46      0.45        89\n",
      "        high       0.62      0.63      0.62        94\n",
      "\n",
      "    accuracy                           0.54       274\n",
      "   macro avg       0.54      0.54      0.54       274\n",
      "weighted avg       0.54      0.54      0.54       274\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.734\tKappa: 0.31\tAccuracy: 0.54\n",
      "------------------------------------------------------\n",
      "\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[56 16  3]\n",
      " [27 23 12]\n",
      " [ 8 12 46]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.62      0.75      0.67        75\n",
      "      medium       0.45      0.37      0.41        62\n",
      "        high       0.75      0.70      0.72        66\n",
      "\n",
      "    accuracy                           0.62       203\n",
      "   macro avg       0.61      0.60      0.60       203\n",
      "weighted avg       0.61      0.62      0.61       203\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.798\tKappa: 0.418\tAccuracy: 0.616\n",
      "------------------------------------------------------\n",
      "\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[38 13 12]\n",
      " [24 21 22]\n",
      " [10 14 47]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.53      0.60      0.56        63\n",
      "      medium       0.44      0.31      0.37        67\n",
      "        high       0.58      0.66      0.62        71\n",
      "\n",
      "    accuracy                           0.53       201\n",
      "   macro avg       0.52      0.53      0.52       201\n",
      "weighted avg       0.52      0.53      0.52       201\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.719\tKappa: 0.29\tAccuracy: 0.527\n",
      "------------------------------------------------------\n",
      "\n",
      "Average scores:\n",
      "\n",
      " Average AUC: 0.736\t Average Kappa: 0.321\t Average Accuracy: 0.548\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "enojo_clasif, enojo_learned_labels, enojo_score = run(df_downsampled_enojo, 'anger', angry_pipeline())\n",
    "miedo_clasif, miedo_learned_labels, miedo_score = run(df_downsampled_miedo, 'fear', fear_pipeline())\n",
    "alegria_clasif, alegria_learned_labels, alegria_score = run(df_downsampled_alegria, 'joy', joy_pipeline())\n",
    "tristeza_clasif, tristeza_learned_labels, tristeza_score = run(df_downsampled_tristeza, 'sadness', sad_pipeline())\n",
    "    \n",
    "# Get clasif/labels/scores\n",
    "classifiers = [enojo_clasif, miedo_clasif, alegria_clasif, tristeza_clasif]\n",
    "learned_labels_array = [enojo_learned_labels, miedo_learned_labels, alegria_learned_labels, tristeza_learned_labels]\n",
    "scores_array = [enojo_score, miedo_score, alegria_score, tristeza_score]\n",
    "\n",
    "# print avg scores\n",
    "print(\n",
    "    \"Average scores:\\n\\n\",\n",
    "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\"\n",
    "    .format(*np.array(scores_array).mean(axis=0)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:37:43.169737Z",
     "start_time": "2019-08-21T19:37:43.166744Z"
    },
    "id": "9kKHJB1hvKgc",
    "colab_type": "text"
   },
   "source": [
    "### Predecir los target set y crear la submission\n",
    "\n",
    "Aquí predecimos los target set usando los clasificadores creados y creamos los archivos de las submissions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.392097Z",
     "start_time": "2020-04-07T15:44:21.386114Z"
    },
    "id": "J2n-WL2VvKgd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def predict_target(dataset, classifier, labels):\n",
    "    # Predecir las probabilidades de intensidad de cada elemento del target set.\n",
    "    predicted = pd.DataFrame(classifier.predict_proba(dataset.tweet), columns=labels)\n",
    "    # Agregar ids\n",
    "    predicted['id'] = dataset.id.values\n",
    "    # Reordenar las columnas\n",
    "    predicted = predicted[['id', 'low', 'medium', 'high']]\n",
    "    return predicted"
   ],
   "execution_count": 79,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.588573Z",
     "start_time": "2020-04-07T15:44:21.394094Z"
    },
    "scrolled": true,
    "id": "67FPoKJUvKgk",
    "colab_type": "code",
    "outputId": "5e155771-9e5c-4360-b3dd-d0a66ae597ba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    }
   },
   "source": [
    "predicted_target = {}\n",
    "\n",
    "# Crear carpeta ./predictions\n",
    "if (not os.path.exists('./predictions')):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "# por cada target set:\n",
    "for idx, key in enumerate(target):\n",
    "    # Predecirlo\n",
    "    predicted_target[key] = predict_target(target[key], classifiers[idx],\n",
    "                                           learned_labels_array[idx])\n",
    "    # Guardar predicciones en archivos separados. \n",
    "    predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n",
    "                                 sep='\\t',\n",
    "                                 header=False,\n",
    "                                 index=False)\n",
    "\n",
    "# Crear archivo zip\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ],
   "execution_count": 80,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1772 features per sample; expecting 2305",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-80-6c45778a5605>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[1;31m# Predecirlo\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     predicted_target[key] = predict_target(target[key], classifiers[idx],\n\u001B[1;32m---> 16\u001B[1;33m                                            learned_labels_array[idx])\n\u001B[0m\u001B[0;32m     17\u001B[0m     \u001B[1;31m# Guardar predicciones en archivos separados.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m     predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n",
      "\u001B[1;32m<ipython-input-79-c573160ecbc4>\u001B[0m in \u001B[0;36mpredict_target\u001B[1;34m(dataset, classifier, labels)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredict_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;31m# Predecir las probabilidades de intensidad de cada elemento del target set.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0mpredicted\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtweet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[1;31m# Agregar ids\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mpredicted\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'id'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    120\u001B[0m         \u001B[1;31m# update the docstring of the returned function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[0mupdate_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    462\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransform\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwith_final\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    463\u001B[0m             \u001B[0mXt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 464\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    465\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    466\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mif_delegate_has_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelegate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'_final_estimator'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    120\u001B[0m         \u001B[1;31m# update the docstring of the returned function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[0mupdate_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\multiclass.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    371\u001B[0m         \u001B[1;31m# Y[i, j] gives the probability that sample i has the label j.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m         \u001B[1;31m# In the multi-label case, these are not disjoint.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 373\u001B[1;33m         \u001B[0mY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0me\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimators_\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    374\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    375\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimators_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\multiclass.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    371\u001B[0m         \u001B[1;31m# Y[i, j] gives the probability that sample i has the label j.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m         \u001B[1;31m# In the multi-label case, these are not disjoint.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 373\u001B[1;33m         \u001B[0mY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0me\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimators_\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    374\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    375\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimators_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1466\u001B[0m                                                 self.solver == 'liblinear')))\n\u001B[0;32m   1467\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0movr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1468\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_predict_proba_lr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1469\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1470\u001B[0m             \u001B[0mdecision\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36m_predict_proba_lr\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    319\u001B[0m         \u001B[0mmulticlass\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0mhandled\u001B[0m \u001B[0mby\u001B[0m \u001B[0mnormalizing\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mover\u001B[0m \u001B[0mall\u001B[0m \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    320\u001B[0m         \"\"\"\n\u001B[1;32m--> 321\u001B[1;33m         \u001B[0mprob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    322\u001B[0m         \u001B[0mexpit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprob\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprob\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    323\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mprob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Workspace\\Python\\Envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mdecision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    285\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    286\u001B[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001B[1;32m--> 287\u001B[1;33m                              % (X.shape[1], n_features))\n\u001B[0m\u001B[0;32m    288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001B[1;31mValueError\u001B[0m: X has 1772 features per sample; expecting 2305"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG1HKffVvKgq",
    "colab_type": "text"
   },
   "source": [
    "## 6. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTJLC8nNvKgr",
    "colab_type": "text"
   },
   "source": [
    "..."
   ]
  }
 ]
}